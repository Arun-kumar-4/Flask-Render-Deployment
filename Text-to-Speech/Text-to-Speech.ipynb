{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab6d51c-a2ae-4eba-855c-c705712bef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/43.7 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------- ----------- 30.7/43.7 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------- ----------- 30.7/43.7 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------- ----------- 30.7/43.7 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.7/43.7 kB 142.8 kB/s eta 0:00:00\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.7.24-cp38-cp38-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/41.5 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 41.5/41.5 kB 496.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.4-cp38-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp38-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.4 MB 640.0 kB/s eta 0:00:15\n",
      "   ---------------------------------------- 0.1/9.4 MB 812.7 kB/s eta 0:00:12\n",
      "   ---------------------------------------- 0.1/9.4 MB 777.7 kB/s eta 0:00:13\n",
      "   ---------------------------------------- 0.1/9.4 MB 777.7 kB/s eta 0:00:13\n",
      "   ---------------------------------------- 0.1/9.4 MB 777.7 kB/s eta 0:00:13\n",
      "    --------------------------------------- 0.1/9.4 MB 500.5 kB/s eta 0:00:19\n",
      "    --------------------------------------- 0.2/9.4 MB 621.6 kB/s eta 0:00:15\n",
      "   - -------------------------------------- 0.3/9.4 MB 714.4 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.3/9.4 MB 714.4 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.3/9.4 MB 631.2 kB/s eta 0:00:15\n",
      "   - -------------------------------------- 0.4/9.4 MB 694.6 kB/s eta 0:00:14\n",
      "   - -------------------------------------- 0.5/9.4 MB 800.3 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.6/9.4 MB 906.5 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.6/9.4 MB 910.6 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.7/9.4 MB 945.5 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.8/9.4 MB 996.7 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.9/9.4 MB 1.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.0/9.4 MB 1.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.1/9.4 MB 1.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.1/9.4 MB 1.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.2/9.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.4/9.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.4/9.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.5/9.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.6/9.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.7/9.4 MB 1.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.8/9.4 MB 1.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 1.9/9.4 MB 1.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.0/9.4 MB 1.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.1/9.4 MB 1.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.2/9.4 MB 1.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.3/9.4 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.4/9.4 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.4/9.4 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.5/9.4 MB 1.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.6/9.4 MB 1.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.7/9.4 MB 1.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.8/9.4 MB 1.5 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.9/9.4 MB 1.5 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.0/9.4 MB 1.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.1/9.4 MB 1.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.2/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.3/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.3/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.5/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.5/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.6/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.7/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.8/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.9/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.0/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.1/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.1/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.2/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.3/9.4 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.4/9.4 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.5/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.6/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.7/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.8/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.9/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.0/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.1/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.2/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.3/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.4/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.5/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.6/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.7/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.7/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.8/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.9/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.0/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.1/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.2/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.3/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.4/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.5/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.6/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.6/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.7/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.8/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.9/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.0/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.1/9.4 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.2/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.3/9.4 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.4/9.4 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.5/9.4 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.5/9.4 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.6/9.4 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.7/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.8/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.0/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.0/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.2/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.2/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.2/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.4/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.5/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.6/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.8/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.0/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.1/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "   ---------------------------------------- 0.0/417.5 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/417.5 kB 960.0 kB/s eta 0:00:01\n",
      "   ------------- -------------------------- 143.4/417.5 kB 1.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 225.3/417.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 297.0/417.5 kB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 399.4/417.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 417.5/417.5 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading regex-2024.7.24-cp38-cp38-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.7 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 71.7/269.7 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 153.6/269.7 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  266.2/269.7 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.7/269.7 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.4-cp38-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.2 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 92.2/286.2 kB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 174.1/286.2 kB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 256.0/286.2 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 286.2/286.2 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp38-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.2 MB 2.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/2.2 MB 2.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.4/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.9/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.1/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.5/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.7/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.9/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "   ---------------------------------------- 0.0/177.6 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 81.9/177.6 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  174.1/177.6 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 177.6/177.6 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.15.4 fsspec-2024.6.1 huggingface-hub-0.24.5 regex-2024.7.24 safetensors-0.4.4 tokenizers-0.19.1 transformers-4.43.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c8dd6b-7175-4355-a746-d8c7b3703d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c48b8-c6fb-4267-8618-d963c82b43e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6020c8a8-c409-49cf-a7c1-df932fdd8545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269442f070c04ddca021e40585e1ff91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\arunkumars\\.cache\\huggingface\\hub\\models--ai4bharat--IndicBART. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1374ba86de448b492dd7141627de719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/832 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "\nAlbertTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize tokenizer and model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mai4bharat/IndicBART\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_lower_case\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_accents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai4bharat/IndicBART\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Some initial mapping\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:896\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    893\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m         )\n\u001b[1;32m--> 896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    898\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\utils\\import_utils.py:1526\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1526\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\utils\\import_utils.py:1514\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1512\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nAlbertTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, AutoModelForSeq2SeqLM\n",
    "from transformers import AlbertTokenizer, AutoTokenizer\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART\", do_lower_case=False, use_fast=False, keep_accents=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/IndicBART\")\n",
    "\n",
    "# Some initial mapping\n",
    "bos_id = tokenizer._convert_token_to_id_with_added_voc(\"<s>\")\n",
    "eos_id = tokenizer._convert_token_to_id_with_added_voc(\"</s>\")\n",
    "pad_id = tokenizer._convert_token_to_id_with_added_voc(\"<pad>\")\n",
    "lang_ids = {'en': tokenizer._convert_token_to_id_with_added_voc(\"<2en>\"),\n",
    "            'hi': tokenizer._convert_token_to_id_with_added_voc(\"<2hi>\")}\n",
    "\n",
    "def tts_generate(text, lang, filename):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "\n",
    "def process_and_speak(input_text, target_lang):\n",
    "    # Tokenize input and output\n",
    "    inp = tokenizer(f\"{input_text} </s> <2{target_lang}>\", add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids\n",
    "    target_lang_id = lang_ids.get(target_lang, tokenizer._convert_token_to_id_with_added_voc(\"<2en>\")) # default to English\n",
    "    \n",
    "    # Generate output\n",
    "    model_output = model.generate(\n",
    "        inp, use_cache=True, num_beams=4, max_length=20, min_length=1, early_stopping=True, \n",
    "        pad_token_id=pad_id, bos_token_id=bos_id, eos_token_id=eos_id, \n",
    "        decoder_start_token_id=target_lang_id\n",
    "    )\n",
    "    \n",
    "    # Decode and print output\n",
    "    decoded_output = tokenizer.decode(model_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    print(decoded_output)\n",
    "    \n",
    "    # Generate TTS only for English and Hindi\n",
    "    if target_lang in ['en', 'hi']:\n",
    "        lang_code = 'en' if target_lang == 'en' else 'hi'\n",
    "        filename = f\"{target_lang}_output.mp3\"\n",
    "        tts_generate(decoded_output, lang_code, filename)\n",
    "        print(f\"TTS audio saved as {filename}\")\n",
    "\n",
    "# Example usage\n",
    "process_and_speak(\"I am a boy\", \"en\")\n",
    "process_and_speak(\"मैं  एक लड़का हूँ\", \"hi\")\n",
    "process_and_speak(\"मला [MASK] पाहिजे </s> <2mr>\", \"mr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d423a15-131c-4885-aae5-a378d9c74b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d5aa1-9016-43f5-93e6-450d768e82dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f174f7-8dcd-4793-929f-f9bf97215933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf21e5da50e486daf59957b86d8a773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\arunkumars\\.cache\\huggingface\\hub\\models--facebook--bart-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8de32660f14df6bd632ad3a1be57e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f812f46d564eff89e79bc6d1327a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fdf8b73181485aa2382be8f1ddd139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4630fef8d8f4d488f8efe4381064ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize tokenizer and model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BartTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBartForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/bart-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Some initial mapping\u001b[39;00m\n\u001b[0;32m     10\u001b[0m bos_id \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<s>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\modeling_utils.py:3516\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3500\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m   3502\u001b[0m     cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[0;32m   3504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: commit_hash,\n\u001b[0;32m   3515\u001b[0m     }\n\u001b[1;32m-> 3516\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3518\u001b[0m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[0;32m   3519\u001b[0m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[0;32m   3520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[0;32m   3521\u001b[0m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\utils\\hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[0;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:1240\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m   1221\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:1389\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1387\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1399\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:1915\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[1;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[0;32m   1912\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m   1913\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m-> 1915\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1924\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1925\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:549\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[0;32m    547\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 549\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    551\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\urllib3\\response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\urllib3\\response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\urllib3\\response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\urllib3\\response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\http\\client.py:458\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    457\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 458\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\http\\client.py:502\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    497\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from gtts import gTTS\n",
    "import torch\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "# Some initial mapping\n",
    "bos_id = tokenizer.convert_tokens_to_ids(\"<s>\")\n",
    "eos_id = tokenizer.convert_tokens_to_ids(\"</s>\")\n",
    "pad_id = tokenizer.convert_tokens_to_ids(\"<pad>\")\n",
    "\n",
    "def tts_generate(text, lang, filename):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "\n",
    "def process_and_speak(input_text, target_lang):\n",
    "    # Tokenize input\n",
    "    inp = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    # Generate output\n",
    "    model_output = model.generate(\n",
    "        inp['input_ids'], \n",
    "        use_cache=True, \n",
    "        num_beams=4, \n",
    "        max_length=20, \n",
    "        min_length=1, \n",
    "        early_stopping=True, \n",
    "        pad_token_id=pad_id, \n",
    "        bos_token_id=bos_id, \n",
    "        eos_token_id=eos_id\n",
    "    )\n",
    "    \n",
    "    # Decode and print output\n",
    "    decoded_output = tokenizer.decode(model_output[0], skip_special_tokens=True)\n",
    "    print(decoded_output)\n",
    "    \n",
    "    # Generate TTS only for English and Hindi\n",
    "    if target_lang in ['en', 'hi']:\n",
    "        lang_code = 'en' if target_lang == 'en' else 'hi'\n",
    "        filename = f\"{target_lang}_output.mp3\"\n",
    "        tts_generate(decoded_output, lang_code, filename)\n",
    "        print(f\"TTS audio saved as {filename}\")\n",
    "\n",
    "# Example usage\n",
    "process_and_speak(\"I am a boy\", \"en\")\n",
    "process_and_speak(\"मैं  एक लड़का हूँ\", \"hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bca563-1592-45bd-bc2a-895a5922cdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2866fc5-0281-4cdf-a291-2d838394e0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.0\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece\n",
    "print(sentencepiece.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fac88562-9777-4cc3-9287-98c3ae8eb7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text to process:  मेरा नाम है\n",
      "Enter the target language (en/hi):  en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output: मेरा नाम है\n",
      "TTS audio saved as en_output.mp3\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from gtts import gTTS\n",
    "import torch\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "# Some initial mapping\n",
    "bos_id = tokenizer.convert_tokens_to_ids(\"<s>\")\n",
    "eos_id = tokenizer.convert_tokens_to_ids(\"</s>\")\n",
    "pad_id = tokenizer.convert_tokens_to_ids(\"<pad>\")\n",
    "\n",
    "def tts_generate(text, lang, filename):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "\n",
    "def process_and_speak(input_text, target_lang):\n",
    "    # Tokenize input\n",
    "    inp = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    # Generate output\n",
    "    model_output = model.generate(\n",
    "        inp['input_ids'], \n",
    "        use_cache=True, \n",
    "        num_beams=4, \n",
    "        max_length=20, \n",
    "        min_length=1, \n",
    "        early_stopping=True, \n",
    "        pad_token_id=pad_id, \n",
    "        bos_token_id=bos_id, \n",
    "        eos_token_id=eos_id\n",
    "    )\n",
    "    \n",
    "    # Decode and print output\n",
    "    decoded_output = tokenizer.decode(model_output[0], skip_special_tokens=True)\n",
    "    print(\"Generated Output:\", decoded_output)\n",
    "    \n",
    "    # Generate TTS only for English and Hindi\n",
    "    if target_lang in ['en', 'hi']:\n",
    "        lang_code = 'en' if target_lang == 'en' else 'hi'\n",
    "        filename = f\"{target_lang}_output.mp3\"\n",
    "        tts_generate(decoded_output, lang_code, filename)\n",
    "        print(f\"TTS audio saved as {filename}\")\n",
    "\n",
    "# User input\n",
    "input_text = input(\"Enter the text to process: \")\n",
    "target_lang = input(\"Enter the target language (en/hi): \").strip().lower()\n",
    "\n",
    "# Process and speak\n",
    "process_and_speak(input_text, target_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07161cb3-8905-42e5-bbec-50fdf93d0ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text to process (in English):  how are you\n",
      "Enter the target language (en/hi):  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output: how are you\n",
      "TTS audio saved as hi_output.mp3\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART\", do_lower_case=False, use_fast=False, keep_accents=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/IndicBART\")\n",
    "\n",
    "# Some initial mapping\n",
    "bos_id = tokenizer._convert_token_to_id_with_added_voc(\"<s>\")\n",
    "eos_id = tokenizer._convert_token_to_id_with_added_voc(\"</s>\")\n",
    "pad_id = tokenizer._convert_token_to_id_with_added_voc(\"<pad>\")\n",
    "lang_ids = {'en': tokenizer._convert_token_to_id_with_added_voc(\"<2en>\"),\n",
    "            'hi': tokenizer._convert_token_to_id_with_added_voc(\"<2hi>\")}\n",
    "\n",
    "def tts_generate(text, lang, filename):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "\n",
    "def process_and_speak(input_text, target_lang):\n",
    "    if target_lang not in ['en', 'hi']:\n",
    "        raise ValueError(\"Target language must be 'en' or 'hi'\")\n",
    "    \n",
    "    # Tokenize input and output\n",
    "    inp = tokenizer(f\"{input_text} </s> <2{target_lang}>\", add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids\n",
    "    target_lang_id = lang_ids.get(target_lang, tokenizer._convert_token_to_id_with_added_voc(\"<2en>\"))  # default to English\n",
    "    \n",
    "    # Generate output\n",
    "    model_output = model.generate(\n",
    "        inp, use_cache=True, num_beams=4, max_length=20, min_length=1, early_stopping=True, \n",
    "        pad_token_id=pad_id, bos_token_id=bos_id, eos_token_id=eos_id, \n",
    "        decoder_start_token_id=target_lang_id\n",
    "    )\n",
    "    \n",
    "    # Decode and print output\n",
    "    decoded_output = tokenizer.decode(model_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    print(\"Generated Output:\", decoded_output)\n",
    "    \n",
    "    # Generate TTS only for English and Hindi\n",
    "    if target_lang in ['en', 'hi']:\n",
    "        lang_code = 'en' if target_lang == 'en' else 'hi'\n",
    "        filename = f\"{target_lang}_output.mp3\"\n",
    "        tts_generate(decoded_output, lang_code, filename)\n",
    "        print(f\"TTS audio saved as {filename}\")\n",
    "\n",
    "# User input\n",
    "input_text = input(\"Enter the text to process (in English): \")\n",
    "target_lang = input(\"Enter the target language (en/hi): \").strip().lower()\n",
    "\n",
    "# Validate language input\n",
    "if target_lang not in ['en', 'hi']:\n",
    "    print(\"Invalid target language. Please choose 'en' for English or 'hi' for Hindi.\")\n",
    "else:\n",
    "    # Process and speak\n",
    "    process_and_speak(input_text, target_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d6bc5c-ea80-4c67-ae5f-2ddad4653c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text to translate (in English):  how are you\n",
      "Enter the target language (hi for Hindi):  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output (Hindi): how are you\n",
      "TTS audio saved as hi_output.mp3\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART\", do_lower_case=False, use_fast=False, keep_accents=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/IndicBART\")\n",
    "\n",
    "# Some initial mapping\n",
    "bos_id = tokenizer.convert_tokens_to_ids(\"<s>\")\n",
    "eos_id = tokenizer.convert_tokens_to_ids(\"</s>\")\n",
    "pad_id = tokenizer.convert_tokens_to_ids(\"<pad>\")\n",
    "lang_ids = {'hi': tokenizer.convert_tokens_to_ids(\"<2hi>\")}  # Hindi language ID\n",
    "\n",
    "def tts_generate(text, lang, filename):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "\n",
    "def process_and_speak(input_text, target_lang):\n",
    "    if target_lang != 'hi':\n",
    "        raise ValueError(\"Currently, only translation to Hindi is supported.\")\n",
    "\n",
    "    # Tokenize input for Hindi translation\n",
    "    inp = tokenizer(f\"{input_text} </s> <2hi>\", add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids\n",
    "    target_lang_id = lang_ids['hi']  # Hindi language ID\n",
    "    \n",
    "    # Generate output\n",
    "    model_output = model.generate(\n",
    "        inp, use_cache=True, num_beams=4, max_length=50, min_length=1, early_stopping=True, \n",
    "        pad_token_id=pad_id, bos_token_id=bos_id, eos_token_id=eos_id, \n",
    "        decoder_start_token_id=target_lang_id\n",
    "    )\n",
    "    \n",
    "    # Decode and print output\n",
    "    decoded_output = tokenizer.decode(model_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    print(\"Generated Output (Hindi):\", decoded_output)\n",
    "    \n",
    "    # Generate TTS only for Hindi\n",
    "    if decoded_output:\n",
    "        lang_code = 'hi'\n",
    "        filename = \"hi_output.mp3\"\n",
    "        tts_generate(decoded_output, lang_code, filename)\n",
    "        print(f\"TTS audio saved as {filename}\")\n",
    "    else:\n",
    "        print(\"No translation was generated.\")\n",
    "\n",
    "# User input\n",
    "input_text = input(\"Enter the text to translate (in English): \")\n",
    "target_lang = input(\"Enter the target language (hi for Hindi): \").strip().lower()\n",
    "\n",
    "# Validate language input\n",
    "if target_lang != 'hi':\n",
    "    print(\"Currently, only translation to Hindi is supported. Please choose 'hi' for Hindi.\")\n",
    "else:\n",
    "    # Process and speak\n",
    "    process_and_speak(input_text, target_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed387f1-b94e-4371-b1cf-a6159e727348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9d7fac-b3e9-4180-9937-b0804056ffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्ते, आप कैसे हैं?\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def translate_text(text, target_lang='hi'):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, dest=target_lang)\n",
    "    return translation.text\n",
    "\n",
    "text = \"Hello, how are you?\"\n",
    "translated_text = translate_text(text, target_lang='hi')\n",
    "print(translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f13307-530a-458f-b20d-41a4a7a4af37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e02380-abcd-4637-b33a-fc6460d697b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Text: नमस्ते, आप कैसे हैं?\n",
      "TTS audio saved as hi_output.mp3\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "\n",
    "def translate_text(text, target_lang='hi'):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, dest=target_lang)\n",
    "    return translation.text\n",
    "\n",
    "def tts_generate(text, lang, filename):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "\n",
    "input_text = \"Hello, how are you?\"\n",
    "translated_text = translate_text(input_text, target_lang='hi')\n",
    "print(\"Translated Text:\", translated_text)\n",
    "\n",
    "tts_generate(translated_text, lang='hi', filename='hi_output.mp3')\n",
    "print(\"TTS audio saved as hi_output.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82384317-a982-4fa7-aebd-8a1891d1e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text to translate (in English):  how are you\n",
      "Enter the target language (e.g., 'hi' for Hindi):  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Text: आप कैसे हैं\n",
      "TTS audio saved as hi_output.mp3\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "\n",
    "def translate_text(text, target_lang='hi'):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, dest=target_lang)\n",
    "    return translation.text\n",
    "\n",
    "def tts_generate(text, lang, filename):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "\n",
    "# User input\n",
    "input_text = input(\"Enter the text to translate (in English): \")\n",
    "target_lang = input(\"Enter the target language (e.g., 'hi' for Hindi): \").strip().lower()\n",
    "\n",
    "# Validate language input\n",
    "if target_lang not in ['hi', 'en']:\n",
    "    print(\"Unsupported target language. Currently, only 'hi' for Hindi and 'en' for English are supported.\")\n",
    "else:\n",
    "    # Translate the text\n",
    "    translated_text = translate_text(input_text, target_lang=target_lang)\n",
    "    print(\"Translated Text:\", translated_text)\n",
    "\n",
    "    # Generate TTS\n",
    "    tts_generate(translated_text, lang=target_lang, filename=f\"{target_lang}_output.mp3\")\n",
    "    print(f\"TTS audio saved as {target_lang}_output.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4ed00a3-4559-470d-956e-91b865b14176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text to translate (in English):  how are you\n",
      "Enter the target language (e.g., 'hi' for Hindi, 'or' for Odia, 'en' for English):  or\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Text: କେମିତି ଅଛନ୍ତି, କେମିତି ଅଛ\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Language not supported: or",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslated Text:\u001b[39m\u001b[38;5;124m\"\u001b[39m, translated_text)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Generate TTS\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mtts_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslated_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtarget_lang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_output.mp3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTS audio saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_lang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_output.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m, in \u001b[0;36mtts_generate\u001b[1;34m(text, lang, filename)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtts_generate\u001b[39m(text, lang, filename):\n\u001b[1;32m---> 10\u001b[0m     tts \u001b[38;5;241m=\u001b[39m \u001b[43mgTTS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     tts\u001b[38;5;241m.\u001b[39msave(filename)\n",
      "File \u001b[1;32mc:\\users\\arunkumars\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gtts\\tts.py:150\u001b[0m, in \u001b[0;36mgTTS.__init__\u001b[1;34m(self, text, tld, lang, slow, lang_check, pre_processor_funcs, tokenizer_func, timeout)\u001b[0m\n\u001b[0;32m    148\u001b[0m     langs \u001b[38;5;241m=\u001b[39m tts_langs()\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m langs:\n\u001b[1;32m--> 150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanguage not supported: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m lang)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;28mstr\u001b[39m(e), exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Language not supported: or"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "\n",
    "def translate_text(text, target_lang='hi'):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, dest=target_lang)\n",
    "    return translation.text\n",
    "\n",
    "def tts_generate(text, lang, filename):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "\n",
    "# User input\n",
    "input_text = input(\"Enter the text to translate (in English): \")\n",
    "target_lang = input(\"Enter the target language (e.g., 'hi' for Hindi, 'or' for Odia, 'en' for English): \").strip().lower()\n",
    "\n",
    "# Validate language input\n",
    "if target_lang not in ['hi', 'or', 'en']:\n",
    "    print(\"Unsupported target language. Currently, only 'hi' for Hindi, 'or' for Odia, and 'en' for English are supported.\")\n",
    "else:\n",
    "    # Translate the text\n",
    "    translated_text = translate_text(input_text, target_lang=target_lang)\n",
    "    print(\"Translated Text:\", translated_text)\n",
    "\n",
    "    # Generate TTS\n",
    "    tts_generate(translated_text, lang=target_lang, filename=f\"{target_lang}_output.mp3\")\n",
    "    print(f\"TTS audio saved as {target_lang}_output.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c58f15-0175-4d15-9b97-de5db56ed7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a51ba851-479a-498e-8c8c-1e46feca5c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text to translate (in English):  how are you\n",
      "Enter the target language (e.g., 'hi' for Hindi, 'ta' for Tamil, 'bn' for Bengali, 'en' for English):  bn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Text: আপনি কেমন আছেন\n",
      "TTS audio saved as bn_output.mp3\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "\n",
    "def translate_text(text, target_lang='hi'):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, dest=target_lang)\n",
    "    return translation.text\n",
    "\n",
    "def tts_generate(text, lang, filename):\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(filename)\n",
    "        print(f\"TTS audio saved as {filename}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in TTS generation: {e}\")\n",
    "\n",
    "# User input\n",
    "input_text = input(\"Enter the text to translate (in English): \")\n",
    "target_lang = input(\"Enter the target language (e.g., 'hi' for Hindi, 'ta' for Tamil, 'bn' for Bengali, 'en' for English): \").strip().lower()\n",
    "\n",
    "# Validate language input\n",
    "supported_langs = {\n",
    "    'hi': 'Hindi',\n",
    "    'ta': 'Tamil',\n",
    "    'bn': 'Bengali',\n",
    "    'en': 'English'\n",
    "}\n",
    "\n",
    "if target_lang not in supported_langs:\n",
    "    print(f\"Unsupported target language. Currently, supported languages are: {', '.join(supported_langs.keys())}.\")\n",
    "else:\n",
    "    # Translate the text\n",
    "    translated_text = translate_text(input_text, target_lang=target_lang)\n",
    "    print(\"Translated Text:\", translated_text)\n",
    "\n",
    "    # Generate TTS\n",
    "    tts_generate(translated_text, lang=target_lang, filename=f\"{target_lang}_output.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf9bbf2-7b78-413b-abe1-ded7dfe43833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8964a79-5e1b-4686-8181-47bc5f359a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text to translate (in English):  hello my name is arun\n",
      "Enter the target language (e.g., 'hi' for Hindi, 'ta' for Tamil, 'bn' for Bengali, 'mr' for Marathi, 'or' for Odia, 'gu' for Gujarati, 'te' for Telugu, 'en' for English):  ta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Text: வணக்கம் என் பெயர் அருண்\n",
      "TTS audio saved as ta_output.wav\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "\n",
    "def translate_text(text, target_lang='hi'):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, dest=target_lang)\n",
    "    return translation.text\n",
    "\n",
    "def tts_generate(text, lang, filename):\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(filename)\n",
    "        print(f\"TTS audio saved as {filename}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in TTS generation: {e}\")\n",
    "\n",
    "# User input\n",
    "input_text = input(\"Enter the text to translate (in English): \")\n",
    "target_lang = input(\"Enter the target language (e.g., 'hi' for Hindi, 'ta' for Tamil, 'bn' for Bengali, 'mr' for Marathi, 'or' for Odia, 'gu' for Gujarati, 'te' for Telugu, 'en' for English): \").strip().lower()\n",
    "\n",
    "# Validate language input\n",
    "supported_langs = {\n",
    "    'hi': 'Hindi',\n",
    "    'ta': 'Tamil',\n",
    "    'bn': 'Bengali',\n",
    "    'mr': 'Marathi',\n",
    "    'or': 'Odia',\n",
    "    'gu': 'Gujarati',\n",
    "    'te': 'Telugu',\n",
    "    'en': 'English'\n",
    "}\n",
    "\n",
    "if target_lang not in supported_langs:\n",
    "    print(f\"Unsupported target language. Currently, supported languages are: {', '.join(supported_langs.keys())}.\")\n",
    "else:\n",
    "    # Translate the text\n",
    "    translated_text = translate_text(input_text, target_lang=target_lang)\n",
    "    print(\"Translated Text:\", translated_text)\n",
    "\n",
    "    # Generate TTS\n",
    "    tts_generate(translated_text, lang=target_lang, filename=f\"{target_lang}_output.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45efafb-8b24-4927-9c5a-2d9862c083f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88deb81-725f-4401-b2d9-a390eac5ca73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1969fa-551e-4d94-a943-b219028a72b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8475104-124f-4094-93ca-4c2ef0718193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf16c9be-757b-4653-826f-1d209b07bc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc75ed0-831c-4db5-a221-809bffcda115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
